# 1.SORT ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œ ë‹¤ì¤‘ ê°ì²´ ì¶”ì ê¸° êµ¬í˜„
ğŸ“– í”„ë¡œì íŠ¸ ì„¤ëª…
* ì´ ì‹¤ìŠµì—ì„œëŠ” SORT ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ì—ì„œ ë‹¤ì¤‘ ê°ì²´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ êµ¬í˜„.
* ì´ë¥¼ í†µí•´ ê°ì²´ ì¶”ì ì˜ ê¸°ë³¸ ê°œë…ê³¼ SORT ì•Œê³ ë¦¬ì¦˜ì˜ ì ìš© ë°©ë²•ì„ í•™ìŠµ.

ğŸ› ï¸ ìš”êµ¬ì‚¬í•­
* ê°ì²´ ê²€ì¶œê¸° êµ¬í˜„: YOLOv4ì™€ ê°™ì€ ì‚¬ì „ í›ˆë ¨ëœ ê°ì²´ ê²€ì¶œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê° í”„ë ˆì„ì—ì„œ ê°ì²´ë¥¼ ê²€ì¶œ
* mathworks.comSORT ì¶”ì ê¸° ì´ˆê¸°í™”: ê²€ì¶œëœ ê°ì²´ì˜ ê²½ê³„ ìƒìë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ SORT ì¶”ì ê¸°ë¥¼ ì´ˆê¸°í™”.
* ê°ì²´ ì¶”ì : ê° í”„ë ˆì„ë§ˆë‹¤ ê²€ì¶œëœ ê°ì²´ì™€ ê¸°ì¡´ ì¶”ì  ê°ì²´ë¥¼ ì—°ê´€ì‹œì¼œ ì¶”ì ì„ ìœ ì§€.
* ê²°ê³¼ ì‹œê°í™”: ì¶”ì ëœ ê° ê°ì²´ì— ê³ ìœ  IDë¥¼ ë¶€ì—¬í•˜ê³ , í•´ë‹¹ IDì™€ ê²½ê³„ ìƒìë¥¼ ë¹„ë””ì˜¤ í”„ë ˆì„ì— í‘œì‹œí•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ
ì¶œë ¥.

## YOLOv4ë¥¼ ì´ìš©í•œ ê°ì²´ ê²€ì¶œê¸° êµ¬í˜„.
```python
def construct_yolo_v4():
    f=open('coco_names.txt', 'r')
    class_names=[line.strip() for line in f.readlines()]
    
    model=cv.dnn.readNet('yolov4.weights', 'yolov4.cfg')
    layer_names=model.getLayerNames()
    out_layers=[layer_names[i-1] for i in model.getUnconnectedOutLayers()]
    
    return model,out_layers,class_names

def yolo_detect(img,yolo_model,out_layers):
    height,width=img.shape[0],img.shape[1]
    test_img=cv.dnn.blobFromImage(img,1.0/256,(448,448),(0,0,0),swapRB=True)
    
    yolo_model.setInput(test_img)
    output3=yolo_model.forward(out_layers)
    
    box,conf,id=[],[],[]    # ë°•ìŠ¤, ì‹ ë¢°ë„, ë¶€ë¥˜ ë²ˆí˜¸
    for output in output3:
        for vec85 in output:
            scores=vec85[5:]
            class_id=np.argmax(scores)
            confidence=scores[class_id]
            if confidence>0.5:    # ì‹ ë¢°ë„ê°€ 50% ì´ìƒì¸ ê²½ìš°ë§Œ ì·¨í•¨
                center_x,center_y=int(vec85[0]*width),int(vec85[1]*height)
                w,h=int(vec85[2]*width),int(vec85[3]*height)
                x,y=int(center_x-w/2),int(center_y-h/2)
                box.append([x,y,x+w,y+h])
                conf.append(float(confidence))
                id.append(class_id)
                
    ind=cv.dnn.NMSBoxes(box,conf,0.5,0.4)
    objects=[box[i]+[conf[i]]+[id[i]] for i in range(len(box)) if i in ind]
    return objects
```

## ê°ì²´ ì¶”ì  ë° ì‹œê°í™”.
```python
model, out_layers, class_names = construct_yolo_v4()
colors = np.random.uniform(0, 255, size=(100, 3))

from sort import Sort

sort = Sort()

cap = cv.VideoCapture(0, cv.CAP_DSHOW)
if not cap.isOpened(): sys.exit('ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨')

while True:
    ret, frame = cap.read()
    if not ret: sys.exit('í”„ë ˆì„ íšë“ì— ì‹¤íŒ¨í•˜ì—¬ ë£¨í”„ë¥¼ ë‚˜ê°‘ë‹ˆë‹¤.')

    res = yolo_detect(frame, model, out_layers)
    persons = [res[i] for i in range(len(res)) if res[i][5]==0]

    if len(persons) == 0:
        tracks = sort.update()
    else :
        tracks = sort.update(np.array(persons))

    for i in range(len(tracks)):
        x1,y1,x2,y2,track_id = tracks[i].astype(int)
        cv.rectangle(frame,(x1,y1),(x2,y2),colors[track_id],2)
        cv.putText(frame,str(track_id),(x1 + 10,y1+40),cv.FONT_HERSHEY_PLAIN,3,colors[track_id],2)

    cv.imshow('Person tracking by SORT',frame)

    key=cv.waitKey(1)
    if key == ord('q'): break

cap.release()
cv.destroyAllWindows()
```

## ì „ì²´ ì½”ë“œ.
```python
import numpy as np
import cv2 as cv
import sys

def construct_yolo_v4():
    f=open('coco_names.txt', 'r')
    class_names=[line.strip() for line in f.readlines()]
    
    model=cv.dnn.readNet('yolov4.weights', 'yolov4.cfg')
    layer_names=model.getLayerNames()
    out_layers=[layer_names[i-1] for i in model.getUnconnectedOutLayers()]
    
    return model,out_layers,class_names

def yolo_detect(img,yolo_model,out_layers):
    height,width=img.shape[0],img.shape[1]
    test_img=cv.dnn.blobFromImage(img,1.0/256,(448,448),(0,0,0),swapRB=True)
    
    yolo_model.setInput(test_img)
    output3=yolo_model.forward(out_layers)
    
    box,conf,id=[],[],[]    # ë°•ìŠ¤, ì‹ ë¢°ë„, ë¶€ë¥˜ ë²ˆí˜¸
    for output in output3:
        for vec85 in output:
            scores=vec85[5:]
            class_id=np.argmax(scores)
            confidence=scores[class_id]
            if confidence>0.5:    # ì‹ ë¢°ë„ê°€ 50% ì´ìƒì¸ ê²½ìš°ë§Œ ì·¨í•¨
                center_x,center_y=int(vec85[0]*width),int(vec85[1]*height)
                w,h=int(vec85[2]*width),int(vec85[3]*height)
                x,y=int(center_x-w/2),int(center_y-h/2)
                box.append([x,y,x+w,y+h])
                conf.append(float(confidence))
                id.append(class_id)
                
    ind=cv.dnn.NMSBoxes(box,conf,0.5,0.4)
    objects=[box[i]+[conf[i]]+[id[i]] for i in range(len(box)) if i in ind]
    return objects

model, out_layers, class_names = construct_yolo_v4()
colors = np.random.uniform(0, 255, size=(100, 3))

from sort import Sort

sort = Sort()

cap = cv.VideoCapture(0, cv.CAP_DSHOW)
if not cap.isOpened(): sys.exit('ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨')

while True:
    ret, frame = cap.read()
    if not ret: sys.exit('í”„ë ˆì„ íšë“ì— ì‹¤íŒ¨í•˜ì—¬ ë£¨í”„ë¥¼ ë‚˜ê°‘ë‹ˆë‹¤.')

    res = yolo_detect(frame, model, out_layers)
    persons = [res[i] for i in range(len(res)) if res[i][5]==0]

    if len(persons) == 0:
        tracks = sort.update()
    else :
        tracks = sort.update(np.array(persons))

    for i in range(len(tracks)):
        x1,y1,x2,y2,track_id = tracks[i].astype(int)
        cv.rectangle(frame,(x1,y1),(x2,y2),colors[track_id],2)
        cv.putText(frame,str(track_id),(x1 + 10,y1+40),cv.FONT_HERSHEY_PLAIN,3,colors[track_id],2)

    cv.imshow('Person tracking by SORT',frame)

    key=cv.waitKey(1)
    if key == ord('q'): break

cap.release()
cv.destroyAllWindows()
```

## ì‹¤í–‰ ê²°ê³¼
![7_1_result.png](https://github.com/wonderdh/ComputerVision/blob/main/7%EC%A3%BC%EC%B0%A8/7_1_result.png)


# 2.Mediapipeë¥¼ í™œìš©í•œ ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ ë° ì‹œê°í™”

ğŸ“– ì„¤ëª…
* Mediapipeì˜ FaceMesh ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ì˜ 468ê°œ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œí•˜ê³ , ì´ë¥¼ ì‹¤ì‹œê°„ ì˜ìƒì— ì‹œê°í™”í•˜ëŠ”
í”„ë¡œê·¸ë¨ì„ êµ¬í˜„.


ğŸ› ï¸ ìš”êµ¬ì‚¬í•­
* Mediapipeì˜ FaceMesh ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œê¸°ë¥¼ ì´ˆê¸°.
* OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ìº ìœ¼ë¡œë¶€í„° ì‹¤ì‹œê°„ ì˜ìƒì„ ìº¡ì²˜.
* ê²€ì¶œëœ ì–¼êµ´ ëœë“œë§ˆí¬ë¥¼ ì‹¤ì‹œê°„ ì˜ìƒì— ì ìœ¼ë¡œ í‘œì‹œ.
* ESC í‚¤ë¥¼ ëˆ„ë¥´ë©´ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ë„ë¡ ì„¤ì •.

## FaceMesh.
```python
mp_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils
mp_styles = mp.solutions.drawing_styles

mesh = mp_mesh.FaceMesh(
    max_num_faces=2,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)
```

* max_num_faces=2 (ì–¼êµ´ì„ 2ê°œê¹Œì§€ ì²˜ë¦¬)
* refine_landmarks=True (ëˆˆê³¼ ì… ëœë“œë§ˆí¬ë¥¼ ì •êµí•˜ê²Œ)
* min_detection_confidence=0.5 (ì–¼êµ´ê²€ì¶œ ì‹ ë¢°ë„ê°€ 0.5 ì´ìƒì¼ ë•Œ ì„±ê³µìœ¼ë¡œ ê°„ì£¼)
* min_tracking_confidence=0.5 (ëœë“œë§ˆí¬ ì¶”ì  ì‹ ë¢°ë„ê°€ 0.5ë³´ë‹¤ ì‘ìœ¼ë©´ ì‹¤íŒ¨ â†’ ì–¼êµ´ê²€ì¶œ ì¬ìˆ˜í–‰)

## ì „ì²´ ì½”ë“œ.
```python
import cv2 as cv
import mediapipe as mp

mp_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils
mp_styles = mp.solutions.drawing_styles

mesh = mp_mesh.FaceMesh(
    max_num_faces=2,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

cap = cv.VideoCapture(0, cv.CAP_DSHOW)

while True:
    ret, frame = cap.read()
    if not ret:
        print('í”„ë ˆì„ íšë“ì— ì‹¤íŒ¨í•˜ì—¬ ë£¨í”„ë¥¼ ë‚˜ê°‘ë‹ˆë‹¤.')
        break
    
    res = mesh.process(cv.cvtColor(frame, cv.COLOR_BGR2RGB))
    
    if res.multi_face_landmarks:
        for landmarks in res.multi_face_landmarks:
            mp_drawing.draw_landmarks(
                image=frame,
                landmark_list=landmarks,
                connections=mp_mesh.FACEMESH_TESSELATION,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp_styles.get_default_face_mesh_tesselation_style()
            )
            
            mp_drawing.draw_landmarks(
                image=frame,
                landmark_list=landmarks,
                connections=mp_mesh.FACEMESH_CONTOURS,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp_styles.get_default_face_mesh_contours_style()
            )
            
            mp_drawing.draw_landmarks(
                image=frame,
                landmark_list=landmarks,
                connections=mp_mesh.FACEMESH_IRISES,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp_styles.get_default_face_mesh_iris_connections_style()
            )
    
    cv.imshow('MediaPipe Face Mesh', cv.flip(frame, 1))
    
    if cv.waitKey(5) == 27:
        break

cap.release()
cv.destroyAllWindows()
```

## ì˜ˆì¸¡ ê²°ê³¼
![7_2_result.png](https://github.com/wonderdh/ComputerVision/blob/main/7%EC%A3%BC%EC%B0%A8/7_2_result.png)



