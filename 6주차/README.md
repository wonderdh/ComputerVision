# 1.ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° êµ¬í˜„
ğŸ“– í”„ë¡œì íŠ¸ ì„¤ëª…
* ì†ê¸€ì”¨ ìˆ«ì ì´ë¯¸ì§€(MNIST ë°ì´í„°ì…‹)ë¥¼ ì´ìš©í•˜ì—¬ ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°ë¥¼ êµ¬í˜„.

ğŸ› ï¸ ìš”êµ¬ì‚¬í•­
* MNIST ë°ì´í„°ì…‹ì„ ë¡œë“œ.
* ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• .
* ê°„ë‹¨í•œ ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì¶•.
* ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê³  ì •í™•ë„ë¥¼ í‰ê°€.

## MNIST ë°ì´í„°ì…‹ ë¡œë“œ í›„ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• .
```python
(x_train, y_train), (x_test, y_test) = mnist.load_data()
```

## ê°„ë‹¨í•œ ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì¶•.
```python
model = Sequential([
    Flatten(input_shape=(28, 28)),    # 28x28 ì´ë¯¸ì§€ë¥¼ 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
    Dense(128, activation='relu'),    # ì€ë‹‰ì¸µ: 128ê°œì˜ ë‰´ëŸ°, ReLU í™œì„±í™” í•¨ìˆ˜
    Dense(10, activation='softmax')   # ì¶œë ¥ì¸µ: 10ê°œì˜ ë‰´ëŸ° (0~9 ìˆ«ì í´ë˜ìŠ¤), Softmax í™œì„±í™” í•¨ìˆ˜
])
```

## ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê³  ì •í™•ë„ë¥¼ í‰ê°€.
```python
model.compile(
    optimizer='adam',                        # Adam ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©
    loss='sparse_categorical_crossentropy',  # ì†ì‹¤ í•¨ìˆ˜: ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ CrossEntropy
    metrics=['accuracy']                     # í‰ê°€ ì§€í‘œ: ì •í™•ë„
)

# ëª¨ë¸ í›ˆë ¨
print("ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
model.fit(x_train, y_train, epochs=5, batch_size=32)

# ëª¨ë¸ í‰ê°€
print("ëª¨ë¸ í‰ê°€...")
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}")
```

## ì „ì²´ ì½”ë“œ
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.datasets import mnist

# 1. MNIST ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# ë°ì´í„° ì •ê·œí™” (í”½ì…€ ê°’ì„ 0~1ë¡œ ìŠ¤ì¼€ì¼ë§)
x_train = x_train / 255.0
x_test = x_test / 255.0

# 2. ê°„ë‹¨í•œ ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì¶•
model = Sequential([
    Flatten(input_shape=(28, 28)),  # 28x28 ì´ë¯¸ì§€ë¥¼ 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
    Dense(128, activation='relu'), # ì€ë‹‰ì¸µ: 128ê°œì˜ ë‰´ëŸ°, ReLU í™œì„±í™” í•¨ìˆ˜
    Dense(10, activation='softmax') # ì¶œë ¥ì¸µ: 10ê°œì˜ ë‰´ëŸ° (0~9 ìˆ«ì í´ë˜ìŠ¤), Softmax í™œì„±í™” í•¨ìˆ˜
])

# ëª¨ë¸ ìš”ì•½ ì¶œë ¥
model.summary()

# 3. ëª¨ë¸ ì»´íŒŒì¼
model.compile(
    optimizer='adam',              # Adam ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©
    loss='sparse_categorical_crossentropy', # ì†ì‹¤ í•¨ìˆ˜: ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ CrossEntropy
    metrics=['accuracy']           # í‰ê°€ ì§€í‘œ: ì •í™•ë„
)

# 4. ëª¨ë¸ í›ˆë ¨
print("ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
model.fit(x_train, y_train, epochs=5, batch_size=32)

# 5. ëª¨ë¸ í‰ê°€
print("ëª¨ë¸ í‰ê°€...")
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}")

```

## ì‹¤í–‰ ê²°ê³¼
![6_1_result.png](https://github.com/wonderdh/ComputerVision/blob/main/6%EC%A3%BC%EC%B0%A8/6_1_result.png)
![6_1_2_result.png](https://github.com/wonderdh/ComputerVision/blob/main/6%EC%A3%BC%EC%B0%A8/6_1_2_result.png)


# 2.CIFAR-10 ë°ì´í„°ì…‹ì„ í™œìš©í•œ CNN ëª¨ë¸ êµ¬ì¶•

ğŸ“– ì„¤ëª…
* CIFAR-10 ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ í•©ì„±ê³± ì‹ ê²½ë§(CNN)ì„ êµ¬ì¶•í•˜ê³ , ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰.


ğŸ› ï¸ ìš”êµ¬ì‚¬í•­
* CIFAR-10 ë°ì´í„°ì…‹ì„ ë¡œë“œ.
* ë°ì´í„° ì „ì²˜ë¦¬(ì •ê·œí™” ë“±)ë¥¼ ìˆ˜í–‰.
* CNN ëª¨ë¸ì„ ì„¤ê³„í•˜ê³  í›ˆë ¨.
* ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰

## CIFAR-10 ë°ì´í„°ì…‹ì„ ë¡œë“œ.
```python
# 1. CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
```

## ë°ì´í„° ì „ì²˜ë¦¬(ì •ê·œí™” ë“±)ë¥¼ ìˆ˜í–‰.
```python
# 2. ë°ì´í„° ì „ì²˜ë¦¬: í”½ì…€ ê°’ì„ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
x_train, x_test = x_train / 255.0, x_test / 255.0

# í´ë˜ìŠ¤ ë ˆì´ë¸”ì„ ì›-í•« ì¸ì½”ë”©ìœ¼ë¡œ ë³€í™˜
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)
```

## CNN ëª¨ë¸ì„ ì„¤ê³„.
```python
# 3. CNN ëª¨ë¸ ì„¤ê³„
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])
```

## ì„¤ê³„ëœ CNN ëª¨ë¸ì„ í›ˆë ¨.
```python
# 3. CNN ëª¨ë¸ ì„¤ê³„
# 4. ëª¨ë¸ ì»´íŒŒì¼
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 5. ëª¨ë¸ í›ˆë ¨
model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))
```

## ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€.
```python
# 6. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
loss, accuracy = model.evaluate(x_test, y_test)
print(f"Test Loss: {loss}, Test Accuracy: {accuracy}")
```

## ì˜ˆì¸¡ ê²°ê³¼
![6_2_2_result.png](https://github.com/wonderdh/ComputerVision/blob/main/6%EC%A3%BC%EC%B0%A8/6_2_2_result.png)


## í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰
```python
# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì˜ˆì¸¡
predictions = model.predict(x_test[:5])  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¼ë¶€ì— ëŒ€í•´ ì˜ˆì¸¡ ìˆ˜í–‰
print("Predictions:", predictions)
```

## ì˜ˆì¸¡ ê²°ê³¼
![6_2_1_result.png](https://github.com/wonderdh/ComputerVision/blob/main/6%EC%A3%BC%EC%B0%A8/6_2_1_result.png)

## ê²°ê³¼ í•´ì„
CNN ëª¨ë¸ì˜ predictions ì¶œë ¥ ê²°ê³¼ëŠ” ê° í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ í´ë˜ìŠ¤ë³„ í™•ë¥  ë¶„í¬ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì˜ë¯¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

1. predictions ì¶œë ¥ êµ¬ì¡°
* predictionsëŠ” 5ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í¬í•¨í•©ë‹ˆë‹¤ (x_test[:5]ë¡œ 5ê°œ ì´ë¯¸ì§€ ì„ íƒ).

* ê° ì´ë¯¸ì§€ì— ëŒ€í•´ 10ê°œì˜ ìˆ«ìê°€ ì¶œë ¥ë˜ë©°, ì´ëŠ” CIFAR-10ì˜ 10ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ê°’ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

ì˜ˆ: predictions = [0.02, 0.01, 0.1, 0.05, 0.7, 0.01, 0.0, 0.05, 0.02, 0.04]

2. ìˆ«ìì˜ ì˜ë¯¸
* ê° ìˆ«ì: í•´ë‹¹ í´ë˜ìŠ¤ì— ì†í•  í™•ë¥  (0~1 ì‚¬ì´ ê°’).

* softmax í™œì„±í™” í•¨ìˆ˜ë¡œ ì¸í•´ ëª¨ë“  í™•ë¥ ì˜ í•©ì€ 1ì´ ë©ë‹ˆë‹¤.

* ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ê°€ ëª¨ë¸ì˜ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ì…ë‹ˆë‹¤.

ì˜ˆì‹œ:
predictions = [0.02, 0.01, 0.1, 0.05, 0.7, 0.01, 0.0, 0.05, 0.02, 0.04]
â†’ 4ë²ˆì§¸ ì¸ë±ìŠ¤(0.7)ê°€ ê°€ì¥ ë†’ìœ¼ë¯€ë¡œ í´ë˜ìŠ¤ 4ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
