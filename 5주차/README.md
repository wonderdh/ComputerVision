# 1.SIFTë¥¼ ì´ìš©í•œ íŠ¹ì§•ì  ê²€ì¶œ ë° ì‹œê°í™”
ğŸ“– í”„ë¡œì íŠ¸ ì„¤ëª…

ì£¼ì–´ì§„ ì´ë¯¸ì§€(mot_color70.jpg)ë¥¼ ì´ìš©í•˜ì—¬ SIFT(Scale-Invariant Feature Transform) ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„
ê²€ì¶œí•˜ê³  ì´ë¥¼ ì‹œê°í™”


ğŸ› ï¸ ìš”êµ¬ì‚¬í•­
* cv.imread()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°.
* cv.SIFT_create()ë¥¼ ì‚¬ìš©í•˜ì—¬ SIFT ê°ì²´ë¥¼ ìƒì„±.
* detectAndCompute()ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ê²€ì¶œ.
* cv.drawKeypoints()ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ì´ë¯¸ì§€ì— ì‹œê°í™”.
* matplotlibì„ ì´ìš©í•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ì™€ íŠ¹ì§•ì ì´ ì‹œê°í™”ëœ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ ì¶œë ¥.

```python
import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt

img = cv.imread('mot_color70.jpg')

gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) # BGR ì»¬ëŸ¬ ì˜ìƒì„ ëª…ì•” ì˜ìƒìœ¼ë¡œ ë³€í™˜

sift = cv.SIFT.create()
kp, des = sift.detectAndCompute(gray, None)

gray = cv.drawKeypoints(gray, kp, None, flags = cv.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)

result = np.hstack([img, gray])

plt.imshow(result)
plt.show()
```



## ì‹¤í–‰ê²°ê³¼
![5_1_result.png](https://github.com/wonderdh/ComputerVision/blob/main/5%EC%A3%BC%EC%B0%A8/5_1.png)

# 2.SIFTë¥¼ ì´ìš©í•œ ë‘ ì˜ìƒ ê°„ íŠ¹ì§•ì  ë§¤ì¹­

ğŸ“– ì„¤ëª…

ë‘ ê°œì˜ ì´ë¯¸ì§€(mot_color70.jpg, mot_color80.jpg)ë¥¼ ì…ë ¥ë°›ì•„ SIFT íŠ¹ì§•ì  ê¸°ë°˜ìœ¼ë¡œ ë§¤ì¹­ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì‹œê°í™”


ğŸ› ï¸ ìš”êµ¬ì‚¬í•­
* cv.imread()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°.
* cv.SIFT_create()ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ì¶”ì¶œ.
* cv.BFMatcher() ë˜ëŠ” cv.FlannBasedMatcher()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ì˜ìƒ ê°„ íŠ¹ì§•ì ì„ ë§¤ì¹­.
* cv.drawMatches()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤ì¹­ ê²°ê³¼ë¥¼ ì‹œê°í™”.
* matplotlibì„ ì´ìš©í•˜ì—¬ ë§¤ì¹­ ê²°ê³¼ë¥¼ ì¶œë ¥.

```python
import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt

img1 = cv.imread('mot_color70.jpg')[190:350, 440:560]
img2 = cv.imread('mot_color83.jpg')

gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY) # BGR ì»¬ëŸ¬ ì˜ìƒì„ ëª…ì•” ì˜ìƒìœ¼ë¡œ ë³€í™˜
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY) # BGR ì»¬ëŸ¬ ì˜ìƒì„ ëª…ì•” ì˜ìƒìœ¼ë¡œ ë³€í™˜

sift = cv.SIFT.create()

kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)

flann_matcher = cv.FlannBasedMatcher.create()
knn_match = flann_matcher.knnMatch(des1, des2, 2)

T = 0.7
good_match = []
for nearest1, nearest2 in knn_match:
    if(nearest1.distance/nearest2.distance) < T:
        good_match.append(nearest1)

img_match = np.empty((max(img1.shape[0], img2.shape[0]), img1.shape[1] + img2.shape[1], 3), dtype = np.uint8)
cv.drawMatches(img1, kp1, img2, kp2, good_match, img_match, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

cv.imshow('Good Matches', img_match)

k = cv.waitKey()
cv.destroyAllWindows()
```

## ì‹¤í–‰ê²°ê³¼
íŒ½ì°½ ì¹¨ì‹ ì—´ë¦¼ ë‹«í˜ìˆœ
![5_2_result.png](https://github.com/wonderdh/ComputerVision/blob/main/5%EC%A3%BC%EC%B0%A8/5_2.png)

# 3.í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ì •í•© (Image Alignment)

ğŸ“– ì„¤ëª…
* SIFT íŠ¹ì§•ì ì„ ì‚¬ìš©í•˜ì—¬ ë‘ ì´ë¯¸ì§€ ê°„ ëŒ€ì‘ì ì„ ì°¾ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ê³„ì‚°í•˜ì—¬ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ìœ„ì— ì •ë ¬.
* ìƒ˜í”ŒíŒŒì¼ë¡œ img1.jpg, imag2.jpg, imag3.jpg ì¤‘ 2ê°œë¥¼ ì„ íƒ.


ğŸ› ï¸ ìš”êµ¬ì‚¬í•­
* cv.imread()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
* cv.SIFT_create()ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ê²€ì¶œí•©ë‹ˆë‹¤.
* cv.BFMatcher()ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ë§¤ì¹­í•©ë‹ˆë‹¤.
* cv.findHomography()ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
* cv.warpPerspective()ë¥¼ ì‚¬ìš©í•˜ì—¬ í•œ ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•˜ì—¬ ë‹¤ë¥¸ ì´ë¯¸ì§€ì™€ ì •ë ¬í•©ë‹ˆë‹¤.
* ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ì™€ ë¹„êµí•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.

```python
import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt

# ë‘ ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤ 
img1 = cv.imread('img1.jpg')
img2 = cv.imread('img2.jpg')

# BGR ì»¬ëŸ¬ ì˜ìƒì„ ëª…ì•” ì˜ìƒìœ¼ë¡œ ë³€í™˜
gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)

# SIFT íŠ¹ì§•ì  ê²€ì¶œê¸°ë¥¼ ìƒì„±í•˜ê³  íŠ¹ì§•ì ì„ ê²€ì¶œí•©ë‹ˆë‹¤
sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)

# BFMatcherë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ë§¤ì¹­í•©ë‹ˆë‹¤ (ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ìˆ˜ì •)
bf_matcher = cv.BFMatcher()
knn_match = bf_matcher.knnMatch(des1, des2, 2)

# ì¢‹ì€ ë§¤ì¹­ì ë§Œ ì„ íƒí•©ë‹ˆë‹¤
T = 0.7
good_match = []
for nearest1, nearest2 in knn_match:
    if (nearest1.distance / nearest2.distance) < T:
        good_match.append(nearest1)

# ë§¤ì¹­ëœ íŠ¹ì§•ì ì˜ ì¢Œí‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤
points1 = np.float32([kp1[gm.queryIdx].pt for gm in good_match])
points2 = np.float32([kp2[gm.trainIdx].pt for gm in good_match])  # trainIdx ìˆ˜ì •

# RANSACì„ ì‚¬ìš©í•˜ì—¬ í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤
H, _ = cv.findHomography(points1, points2, cv.RANSAC)

# ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
h1, w1 = img1.shape[0], img1.shape[1]
h2, w2 = img2.shape[0], img2.shape[1]

# warpPerspectiveë¥¼ ì‚¬ìš©í•˜ì—¬ img1ì„ img2ì˜ ê´€ì ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤
img1_warped = cv.warpPerspective(img1, H, (w2, h2))

overlay = cv.addWeighted(img1, 0.5, img1_warped, 0.5, 0)

# ë§¤ì¹­ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤
img_match = np.empty((max(h1, h2), w1 + w2, 3), dtype=np.uint8)
cv.drawMatches(img1, kp1, img2, kp2, good_match, img_match, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

# ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤
cv.imshow('Matching', img_match)
cv.imshow('Overlay', overlay)

k = cv.waitKey(0)
cv.destroyAllWindows()
```

## ì‹¤í–‰ê²°ê³¼
SIFT ë§¤ì¹­
![5_3_1_result.png](https://github.com/wonderdh/ComputerVision/blob/main/5%EC%A3%BC%EC%B0%A8/5_3_1.png)
ì›ë³¸ ì´ë¯¸ì§€
![5_3_2_result.png](https://github.com/wonderdh/ComputerVision/blob/main/5%EC%A3%BC%EC%B0%A8/5_3_2.png)
ë³€í™˜ëœ ì´ë¯¸ì§€
![5_3_3_result.png](https://github.com/wonderdh/ComputerVision/blob/main/5%EC%A3%BC%EC%B0%A8/5_3_3.png)




